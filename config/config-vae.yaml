# ==================== CONFIG VAE AMÉLIORÉ ====================
# Date: 5 janvier 2026
# Améliorations: Anti-overfitting, régularisation accrue, augmentations renforcées

# === RESUME TRAINING (Optionnel) ===
# Chemin vers un checkpoint (.pt) pour reprendre l'entraînement
# resume: "logs/VAE_XX/best_model.pt" 
resume: "/usr/users/sdim/sdim_31/UX-Key-PFE/logs/VAE_12/best_model.pt"

data:
  data_dir: "/usr/users/sdim/sdim_31/UX-Key-PFE/vae_dataset_scaled"
  archetypes_dir: "/usr/users/sdim/sdim_31/UX-Key-PFE/archetypes_png"  # Wireframes étiquetés pour métriques latentes
  batch_size: 16                    # Requis pour tailles variables
  num_workers: 8                 # Parallélisation I/O
  valid_ratio: 0.2               # 80/20 train/valid split
  seed: 42                       # Reproductibilité
  
  # Gestion mémoire
  max_height: 2048               # Limite hauteur (crop si dépasse)
  
  # === DENOISING (Augmenté pour robustesse) ===
  noise_level: 0.20              # était: 0.15 → +33% bruit gaussien
  
  # === AUGMENTATIONS (Renforcées contre overfitting) ===
  augment: true
  sp_prob: 0.04                  # était: 0.02 → x2 salt-and-pepper
  random_erasing_prob: 0.35      # était: 0.2 → +75% masking
  perspective_p: 0.3             # Perspective transform (inchangé)
  perspective_distortion_scale: 0.12  # était: 0.08 → +50% distortion
  
  # === NOUVELLES AUGMENTATIONS ===
  rotation_degrees: 5            # Rotation légère ±5°
  brightness_jitter: 0.1         # Variation luminosité ±10%
  contrast_jitter: 0.1           # Variation contraste ±10%

# ==================== MODEL ====================
model:
  name: "vae"
  class: "VAE"                   # Doit correspondre à vae_models.py
  latent_dim: 128                # Dimension espace latent
  input_channels: 1              # Grayscale
  dropout_p: 0.15                # Dropout dans decoder
  use_skip_connections: true     # NOUVEAU: Skip connections U-Net (préserve détails)

# ==================== LOSS (Optimisé pour STRUCTURE de l'espace latent) ====================
loss:
  name: "l1"             # VGG + Pixel + KLD
  beta_kld: 1.0                  # β-VAE: CRITIQUE pour clusters structurés + interpolations cohérentes
  warmup_epochs: 100              # KLD warmup 0 → 1.0 (évite posterior collapse)

# ==================== OPTIMIZER (Démarrage plus conservateur) ====================
optim:
  algo: "AdamW"
  params:
    lr: 0.0003                   # était: 0.0005 → -40% (démarrage plus doux)
    weight_decay: 0.0001         # était: 0.00001 → x10 (régularisation L2)
  
  # === SCHEDULER (CosineAnnealingWarmRestarts pour cycles d'apprentissage) ===
  scheduler:
    name: "CosineAnnealingWarmRestarts"  # était: ReduceLROnPlateau
    params:
      T_0: 100                    # Redémarre tous les 10 epochs
      T_mult: 2                  # Double la période après chaque restart
      eta_min: 0.000003           # LR minimum (plancher) - était 3e-05
      verbose: true

# ==================== OPTIMIZATION ====================
optimization:
  lr: 0.0003                     # Répété (legacy)
  weight_decay: 0.0001
  accumulation_steps: 4          # était: 128 → /2 (plus de variance dans gradients)
  mixed_precision: true          # AMP pour vitesse + mémoire
  
  # === MIXUP / CUTMIX (Améliore généralisation) ===
  use_mixup: true                # NOUVEAU: Active Mixup
  mixup_alpha: 0.2               # Paramètre de mélange (0.2 = mélange léger)
  use_cutmix: true               # NOUVEAU: Active CutMix
  cutmix_alpha: 1.0              # Paramètre de découpe
  mix_prob: 0.3                  # NOUVEAU: Probabilité d'appliquer mix (30% des batches)

# ==================== LOGGING ====================
logging:
  logdir: "./logs"
  tensorboard: true              # Active TensorBoard
  log_loss_components: true      # NOUVEAU: Log pixel/vgg/kld séparément
  save_reconstructions_every: 5  # NOUVEAU: Sauvegarde images tous les 5 epochs
  latent_visualization:
    # Frequency (in epochs) to run t-SNE + k-means on the training set
    frequency: 20
    # Maximum number of training samples to encode for the visualization
    max_samples: 500
  # wandb:                       # (Optionnel)
  #   project: "ux-vae-improved"
  #   entity: "your-team"

# ==================== TRAINING ====================
nepochs: 1000                     # Nombre total d'epochs

# ==================== EARLY STOPPING (NOUVEAU) ====================
early_stopping:
  enabled: true                  # Active early stopping
  monitor: "test_SSIM"           # Métrique surveillée (ou "test_ELBO")
  mode: "max"                    # max pour SSIM, min pour ELBO
  patience: 20                   # Arrête si pas d'amélioration 20 epochs
  min_delta: 0.0001              # Amélioration minimale considérée
