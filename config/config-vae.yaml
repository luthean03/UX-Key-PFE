# ==================== CONFIG VAE AMÉLIORÉ ====================
# Date: 5 janvier 2026
# Améliorations: Anti-overfitting, régularisation accrue, augmentations renforcées

# === RESUME TRAINING (Optionnel) ===
# Chemin vers un checkpoint (.pt) pour reprendre l'entraînement
resume: null 

data:
  data_dir: "/usr/users/sdim/sdim_31/UX-Key-PFE/dataset/vae_dataset_scaled"
  archetypes_dir: "/usr/users/sdim/sdim_31/UX-Key-PFE/dataset/archetypes_png_scaled"  # Wireframes étiquetés pour métriques latentes
  batch_size: 16                    # Requis pour tailles variables
  num_workers: 8                 # Parallélisation I/O
  valid_ratio: 0.2               # 80/20 train/valid split
  seed: 42                       # Reproductibilité
  
  # Gestion mémoire
  max_height: 3000               # Limite hauteur (crop si dépasse)
  
  # === DENOISING (Augmenté pour robustesse) ===
  noise_level: 0.20              # était: 0.15 → +33% bruit gaussien
  
  # === AUGMENTATIONS (Renforcées contre overfitting) ===
  augment: true
  sp_prob: 0.04                  # était: 0.02 → x2 salt-and-pepper
  random_erasing_prob: 0.35      # était: 0.2 → +75% masking
  perspective_p: 0.3             # Perspective transform (inchangé)
  perspective_distortion_scale: 0.12  # était: 0.08 → +50% distortion
  
  # === NOUVELLES AUGMENTATIONS ===
  rotation_degrees: 5            # Rotation légère ±5°
  brightness_jitter: 0.1         # Variation luminosité ±10%
  contrast_jitter: 0.1           # Variation contraste ±10%

# ==================== MODEL ====================
model:
  name: "vae"
  class: "VAE"                   # Doit correspondre à vae_models.py
  latent_dim: 128                # Dimension espace latent
  input_channels: 1              # Grayscale
  dropout_p: 0.1                 # Dropout dans decoder (réduit pour VAE pur)
  # use_skip_connections: false  # DÉSACTIVÉ: cause posterior collapse dans un VAE
                                 # (le décodeur "triche" en regardant les pixels d'entrée)

# ==================== LOSS (Optimisé pour espace latent STRUCTURÉ) ====================
# Options: 'l1', 'mse', 'perceptual'
# 'perceptual' = L1 + SSIM + Gradient + Multi-scale (recommandé pour wireframes)
#
# NORMALISATION STANDARD VAE:
# - recon_loss: mean per pixel (~0.01-0.1 pour images bien reconstruites)
# - kld_loss: SUM sur dims latentes, MEAN sur batch (~50-200 au début, ~10-50 après)
#
# Pour équilibrer: beta_kld ~0.0001-0.001 pour clustering, ~0.01 pour génération
loss:
  name: "l1"                     # 'l1', 'mse', ou 'perceptual'
  beta_kld: 0.0005               # AJUSTÉ: recon (~0.05) vs kld (~100) → beta*kld ~ 0.05
  loss_scale: 1                  # Pas de scaling (valeurs naturelles pour debug)
  warmup_epochs: 10              # KLD warmup progressif (évite posterior collapse au début)
  
  # Poids des composantes (uniquement pour name='perceptual')
  lambda_l1: 1.0                 # Précision pixel (reconstruction fidèle)
  lambda_ssim: 0.5               # Similarité structurelle (layouts, blocs)
  lambda_gradient: 0.1           # Préservation des bords (lignes, contours)
  lambda_multiscale: 0.2         # Hiérarchie spatiale (global + détails)
  use_multiscale: true           # Activer loss multi-échelle

# ==================== OPTIMIZER (Démarrage plus conservateur) ====================
optim:
  algo: "AdamW"
  params:
    lr: 0.0003                   # Learning rate initial
    weight_decay: 0.0001         # Régularisation L2
  
  # === SCHEDULER (CosineAnnealingWarmRestarts pour cycles d'apprentissage) ===
  scheduler:
    name: "CosineAnnealingWarmRestarts"
    params:
      T_0: 10                   # Redémarre tous les 100 epochs
      T_mult: 2                  # Double la période après chaque restart
      eta_min: 0.000003          # LR minimum (plancher)
      verbose: true

# ==================== TRAINING OPTIMIZATION ====================
# NOTE: lr et weight_decay sont définis dans optim.params (source unique de vérité)
optimization:
  accumulation_steps: 4          # Gradient accumulation (effective batch = batch_size * accumulation_steps)
  mixed_precision: true          # AMP pour vitesse + mémoire
  
  # === MIXUP / CUTMIX (DÉSACTIVÉ pour VAE) ===
  # Ces techniques sont conçues pour la classification, pas pour les VAE.
  # - Mixup crée des images "fantômes" (0.5*A + 0.5*B) que le VAE apprend à reconstruire
  # - CutMix détruit la cohérence spatiale des wireframes (Header/Footer/Layout)
  # Pour un VAE, on préfère des augmentations géométriques (flip, rotation légère)
  use_mixup: false
  mixup_alpha: 0.2
  use_cutmix: false
  cutmix_alpha: 1.0
  mix_prob: 0.0                  # Désactivé

# ==================== LOGGING ====================
logging:
  logdir: "./logs"
  tensorboard: true
  log_loss_components: true      # Log SSIM/gradient/KLD séparément
  save_reconstructions_every: 5
  latent_visualization:
    frequency: 20                # t-SNE tous les 20 epochs
    max_samples: 500
  # wandb:
  #   project: "ux-vae-improved"
  #   entity: "your-team"

# ==================== TRAINING ====================
nepochs: 100

# ==================== EARLY STOPPING ====================
early_stopping:
  enabled: true
  monitor: "test_SSIM"           # Métrique surveillée (ou "test_ELBO")
  mode: "max"                    # max pour SSIM, min pour ELBO
  patience: 20                   # Arrête si pas d'amélioration 20 epochs
  min_delta: 0.0001              # Amélioration minimale considérée
# ==================== TEST (Inference) ====================
# Utilisé pour tester le modèle entraîné sur des images
# Exécuter avec: python -m src.torchtmpl.main config/config-vae.yaml test
test:
  test_input_dir: "./test/test_input"          # Dossier contenant les images à tester
  test_output_dir: "./test/test_output"        # Dossier pour enregistrer les résultats (grilles de comparaison)
  model_path: "logs/VAE_18/best_model.pt" # Chemin vers le checkpoint du modèle entraîné
# ==================== INTERPOLATION ====================
# Interpolate between two images in latent space
# Exécuter avec: python -m src.torchtmpl.main config/config-vae.yaml interpolate
interpolate:
  image1_path: "./test/test_input/wireframe_2925855_linear.png"  # Chemin à l'image 1
  image2_path: "./test/test_input/wireframe_3024123_linear.png"  # Chemin à l'image 2
  output_dir: "./test/interpolate_output"            # Dossier pour enregistrer la grille d'interpolation
  num_steps: 10                                 # Nombre de frames d'interpolation entre les deux images
  model_path: "logs/VAE_18/best_model.pt"       # Checkpoint du modèle entraîné