# UX-Key-PFE: VAE for UI/UX Wireframe Design Space Learning

![Status](https://img.shields.io/badge/status-research-blue) ![License](https://img.shields.io/badge/license-MIT-green) ![Python](https://img.shields.io/badge/python-3.9+-blue)

## ğŸ¯ Project Overview

**UX-Key-PFE** is a Variational Autoencoder (VAE) trained on mobile UI/UX wireframe layouts for:

- **Clustering** - Automatically group similar design patterns (archetypes)
- **Interpolation** - Smoothly transition between design concepts
- **Generation** - Sample new valid wireframe layouts from latent space
- **Analysis** - Understand structure of design space using latent representations

The model is designed for **variable-size images** (1000-3000px tall, mobile wireframes) using innovative techniques like Spatial Pyramid Pooling and masked normalization.

### Key Features

âœ… **Variable-height input handling** - No artificial resizing, preserves layout proportions  
âœ… **Attention mechanisms** - CBAM (Channel + Spatial) for selective feature learning  
âœ… **Multi-component loss** - SSIM + Gradients + Reconstruction + KLD  
âœ… **Gradient accumulation & mixed precision** - Efficient memory usage  
âœ… **SLURM integration** - Easy cluster deployment  
âœ… **TensorBoard monitoring** - Real-time training visualization  

---

## ğŸ“¦ Installation

### Local Development

```bash
# Clone the repository
git clone https://github.com/your-org/UX-Key-PFE.git
cd UX-Key-PFE

# Create virtual environment
python3.9 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install --upgrade pip
pip install -e .  # Installs torchtmpl + all dependencies

# Verify installation
python -c "import torch; print(f'PyTorch {torch.__version__}')"
python -c "from torchtmpl.models import VAE; print('VAE imported successfully')"
```

### SLURM Cluster

```bash
# Setup on login node
cd /path/to/UX-Key-PFE

# Submit training job
python submit-slurm.py config/config-vae.yaml train
```

### Docker (Optional)

```bash
docker build -t ux-key-pfe .
docker run --gpus all -it ux-key-pfe
```

---

## ğŸš€ Quick Start

### 1. Prepare Data

```bash
# Expected directory structure:
# dataset/
#   â”œâ”€â”€ vae_dataset_scaled/      # Training images (PNG)
#   â”œâ”€â”€ archetypes_png_scaled/   # Reference designs for analysis
#   â””â”€â”€ samir_lom/               # Raw wireframes (JSON)

# If starting from scratch, preprocess wireframes:
python preprocess/json_to_png.py dataset/samir_lom/ dataset/archetypes_png/
python preprocess/scale.py dataset/archetypes_png/ dataset/archetypes_png_scaled/
```

### 2. Configure Training

Edit `config/config-vae.yaml` to customize:

```yaml
data:
  batch_size: 16              # Adjust for GPU memory
  num_workers: 8              # CPU cores for data loading
  augment: true               # Enable augmentations
  
model:
  latent_dim: 128             # Latent space dimensions
  dropout_p: 0.1              # Regularization
  
optim:
  algo: "AdamW"
  params:
    lr: 0.0003                # Learning rate
    weight_decay: 0.0001      # L2 regularization
```

### 3. Train Locally

```bash
# Single GPU training
python -m torchtmpl.main train config/config-vae.yaml

# Monitor with TensorBoard (new terminal)
tensorboard --logdir logs

# Open browser: http://localhost:6006
```

### 4. Evaluate & Analyze

```bash
# Interpolate between designs
python -m torchtmpl.main interpolate config/config-vae.yaml

# Analyze latent space (t-SNE visualization)
python -m torchtmpl.main latent_analysis config/config-vae.yaml

# Output saved to: test_output/
```

---

## ğŸ“Š Architecture

### Encoder
```
Input Image (B, 1, H, W)
    â†“ Conv7x7 + GroupNorm + ReLU + MaxPool
    â†“ ResBlock (64â†’128, stride=2)
    â†“ ResBlock (128â†’256, stride=2)
    â†“ ResBlock (256â†’512, stride=2)
    â†“ Spatial Pyramid Pooling [1, 2, 4]
    â†“ FC layers
    â†“ (Î¼, log ÏƒÂ²) âˆˆ â„^128
```

**Key Features:**
- **GroupNorm** instead of BatchNorm (works with variable batch sizes)
- **CBAM Attention** (channel + spatial) in residual blocks
- **Spatial Pyramid Pooling** handles variable heights â†’ fixed-size latent

### Decoder
```
Latent Code z âˆˆ â„^128
    â†“ FC expand
    â†“ Reshape (256, 32, 16)
    â†“ Upsample 2x + ResBlock
    â†“ Upsample 2x + ResBlock
    â†“ Upsample 2x + ResBlock
    â†“ Upsample 2x + ResBlock
    â†“ Conv1x1 + Sigmoid
    â†“ Reconstruction (B, 1, H, W)
```

### Loss Function

$$\mathcal{L}_{\text{VAE}} = \underbrace{\mathcal{L}_{\text{recon}}}_{\text{SSIM}} + \beta_{\text{KLD}} \cdot \underbrace{D_{\text{KL}}(q_\phi(z|x) || p(z))}_{\text{Regularization}}$$

Where:
- **Reconstruction loss** = SSIM (structural) + L1 (pixel-level)
- **KLD loss** = KL divergence with annealing (warmup over 10 epochs)
- **Î² coefficient** = 1.0 (naturally balanced with sum reduction)

---

## ğŸ“ˆ Results

### Training Curves (Example)

| Metric | Value |
|--------|-------|
| Best SSIM (Validation) | 0.92 |
| Best Reconstruction Loss | 0.034 |
| Best KLD Loss | 0.12 |
| Epochs to Convergence | 150 |
| Training Time (GPU) | 8-12h |

### Qualitative Results

1. **Clustering** - Similar wireframes cluster together in latent space
2. **Smooth Interpolation** - SLERP between designs produces valid layouts
3. **Generation** - Random sampling from N(0, I) produces reasonable wireframes

See `results/` folder for visualizations.

---

## ğŸ” Monitoring & Debugging

### TensorBoard

```bash
tensorboard --logdir logs
# Metrics tracked:
# - loss/recon, loss/kld, loss/total
# - metrics/ssim (validation)
# - learning_rate (scheduler)
# - latent_visualization (t-SNE every 20 epochs)
```

### Console Output

```
Epoch 1/200:
  Train Loss: 0.456 (recon: 0.340, kld: 0.116)
  Valid Loss: 0.512 (recon: 0.390, kld: 0.122)
  SSIM: 0.891 | LR: 3.00e-04
```

### Common Issues

| Issue | Cause | Solution |
|-------|-------|----------|
| OOM Error | Batch too large | Reduce `batch_size` in config |
| KLD â†’ 0 | Posterior collapse | Enable KLD warmup, increase Î² |
| Blurry reconstructions | Loss not converged | Train longer, check SSIM weight |
| GPU memory leak | Data loading issue | Check `num_workers` setting |

---

## ğŸ› ï¸ Development

### Running Tests

```bash
# Install test dependencies
pip install pytest pytest-cov

# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src/torchtmpl --cov-report=html
```

### Code Quality

```bash
# Type checking
mypy src/torchtmpl/ --ignore-missing-imports

# Linting
flake8 src/torchtmpl/ --max-line-length=100

# Formatting
black src/torchtmpl/
```

### Project Structure

```
UX-Key-PFE/
â”œâ”€â”€ config/                    # Configuration files (YAML)
â”œâ”€â”€ dataset/                   # Data directories (git-ignored)
â”œâ”€â”€ logs/                      # Training checkpoints & logs
â”œâ”€â”€ preprocess/               # Data preprocessing scripts
â”œâ”€â”€ src/
â”‚   â””â”€â”€ torchtmpl/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py           # Training entrypoint
â”‚       â”œâ”€â”€ data.py           # DataLoaders & augmentation
â”‚       â”œâ”€â”€ loss.py           # Loss functions
â”‚       â”œâ”€â”€ optim.py          # Optimizers & schedulers
â”‚       â”œâ”€â”€ utils.py          # Utilities (SLERP, checkpoints)
â”‚       â”œâ”€â”€ latent_metrics.py # Latent space analysis
â”‚       â””â”€â”€ models/
â”‚           â”œâ”€â”€ vae_models.py # VAE architecture
â”‚           â””â”€â”€ base_models.py
â”œâ”€â”€ tests/                    # Unit & integration tests
â”œâ”€â”€ AUDIT.md                  # Detailed code audit
â”œâ”€â”€ QUICK_FIXES.md           # Immediate improvements
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ pyproject.toml           # Dependencies
```

---

## ğŸ“ Learning Resources

- **VAE Theory**: [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)
- **Spatial Pyramid Pooling**: [SPP-Net Paper](https://arxiv.org/abs/1406.4729)
- **CBAM Attention**: [CBAM Paper](https://arxiv.org/abs/1807.06521)
- **PyTorch Best Practices**: [PyTorch Docs](https://pytorch.org/)

---

## ğŸ¤ Contributing

We welcome contributions! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/your-feature`)
3. Commit changes (`git commit -am 'Add your feature'`)
4. Push to branch (`git push origin feature/your-feature`)
5. Open Pull Request

Please ensure:
- âœ… Tests pass (`pytest tests/`)
- âœ… Code is formatted (`black` & `flake8`)
- âœ… Type hints added (`mypy`)
- âœ… Docstrings included

See [CONTRIBUTING.md](CONTRIBUTING.md) for details.

---

## ğŸ“ Citation

If you use this project in your research, please cite:

```bibtex
@software{ux_key_pfe_2026,
  title={UX-Key-PFE: VAE for UI/UX Wireframe Design Space},
  author={Your Name},
  year={2026},
  url={https://github.com/your-org/UX-Key-PFE}
}
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™‹ Support

- **Questions?** Open an [Issue](https://github.com/your-org/UX-Key-PFE/issues)
- **Bugs?** Submit a [Bug Report](https://github.com/your-org/UX-Key-PFE/issues)
- **Ideas?** Start a [Discussion](https://github.com/your-org/UX-Key-PFE/discussions)

---

## ğŸ“ Contact

- **Author**: [Your Name]
- **Email**: your.email@example.com
- **LinkedIn**: [Your Profile]

---

**Last Updated**: 17 janvier 2026  
**Status**: Active Research âœ¨
